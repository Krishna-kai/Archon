# Docker Compose profiles:
# - Default (no profile): Starts archon-server, archon-mcp, and archon-frontend
# - Agents are opt-in: archon-agents starts only with the "agents" profile
# Usage:
#   docker compose up                        # Starts server, mcp, frontend (agents disabled)
#   docker compose --profile agents up -d    # Also starts archon-agents

services:
  # Server Service (FastAPI + Socket.IO + Crawling)
  archon-server:
    build:
      context: ./python
      dockerfile: Dockerfile.server
      args:
        BUILDKIT_INLINE_CACHE: 1
        ARCHON_SERVER_PORT: ${ARCHON_SERVER_PORT:-8181}
    container_name: archon-server
    restart: unless-stopped
    ports:
      - "${ARCHON_SERVER_PORT:-8181}:${ARCHON_SERVER_PORT:-8181}"
    environment:
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_SERVICE_KEY=${SUPABASE_SERVICE_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - LOGFIRE_TOKEN=${LOGFIRE_TOKEN:-}
      - SERVICE_DISCOVERY_MODE=docker_compose
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - ARCHON_SERVER_PORT=${ARCHON_SERVER_PORT:-8181}
      - ARCHON_MCP_PORT=${ARCHON_MCP_PORT:-8051}
      - ARCHON_AGENTS_PORT=${ARCHON_AGENTS_PORT:-8052}
      - AGENT_WORK_ORDERS_PORT=${AGENT_WORK_ORDERS_PORT:-8053}
      - AGENTS_ENABLED=${AGENTS_ENABLED:-false}
      - ARCHON_HOST=${HOST:-localhost}
      - MINERU_SERVICE_URL=${MINERU_SERVICE_URL:-}
    networks:
      - app-network
    volumes:
      # SECURITY: Docker socket mounting removed (CVE-2025-9074 - CVSS 9.3)
      # MCP status now monitored via HTTP health checks (secure, portable)
      # To re-enable Docker socket mode (not recommended):
      #   1. Set ENABLE_DOCKER_SOCKET_MONITORING=true in .env
      #   2. Uncomment the line below
      # - /var/run/docker.sock:/var/run/docker.sock # SECURITY RISK: root-equivalent host access
      - ./python/src:/app/src # Mount source code for hot reload
      - ./python/tests:/app/tests # Mount tests for UI test execution
      - ./migration:/app/migration # Mount migration files for version tracking
    extra_hosts:
      - "host.docker.internal:host-gateway"
    command:
      [
        "python",
        "-m",
        "uvicorn",
        "src.server.main:app",
        "--host",
        "0.0.0.0",
        "--port",
        "${ARCHON_SERVER_PORT:-8181}",
        "--reload",
      ]
    healthcheck:
      test:
        [
          "CMD",
          "sh",
          "-c",
          'python -c "import urllib.request; urllib.request.urlopen(''http://localhost:${ARCHON_SERVER_PORT:-8181}/health'')"',
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Lightweight MCP Server Service (HTTP-based)
  archon-mcp:
    build:
      context: ./python
      dockerfile: Dockerfile.mcp
      args:
        BUILDKIT_INLINE_CACHE: 1
        ARCHON_MCP_PORT: ${ARCHON_MCP_PORT:-8051}
    container_name: archon-mcp
    restart: unless-stopped
    ports:
      - "${ARCHON_MCP_PORT:-8051}:${ARCHON_MCP_PORT:-8051}"
    environment:
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_SERVICE_KEY=${SUPABASE_SERVICE_KEY}
      - LOGFIRE_TOKEN=${LOGFIRE_TOKEN:-}
      - SERVICE_DISCOVERY_MODE=docker_compose
      - TRANSPORT=sse
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      # MCP needs to know where to find other services
      - API_SERVICE_URL=http://archon-server:${ARCHON_SERVER_PORT:-8181}
      - AGENTS_ENABLED=${AGENTS_ENABLED:-false}
      - AGENTS_SERVICE_URL=${AGENTS_SERVICE_URL:-http://archon-agents:${ARCHON_AGENTS_PORT:-8052}}
      - ARCHON_MCP_PORT=${ARCHON_MCP_PORT:-8051}
      - ARCHON_SERVER_PORT=${ARCHON_SERVER_PORT:-8181}
      - ARCHON_AGENTS_PORT=${ARCHON_AGENTS_PORT:-8052}
    networks:
      - app-network
    depends_on:
      archon-server:
        condition: service_healthy
        restart: true
    extra_hosts:
      - "host.docker.internal:host-gateway"
    healthcheck:
      test:
        [
          "CMD",
          "sh",
          "-c",
          'python -c "import socket; s=socket.socket(); s.connect((''localhost'', ${ARCHON_MCP_PORT:-8051})); s.close()"',
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s # Give dependencies time to start

  # AI Agents Service (ML/Reranking)
  archon-agents:
    profiles:
      - agents  # Only starts when explicitly using --profile agents
    build:
      context: ./python
      dockerfile: Dockerfile.agents
      args:
        BUILDKIT_INLINE_CACHE: 1
        ARCHON_AGENTS_PORT: ${ARCHON_AGENTS_PORT:-8052}
    container_name: archon-agents
    restart: unless-stopped
    ports:
      - "${ARCHON_AGENTS_PORT:-8052}:${ARCHON_AGENTS_PORT:-8052}"
    environment:
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_SERVICE_KEY=${SUPABASE_SERVICE_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - LOGFIRE_TOKEN=${LOGFIRE_TOKEN:-}
      - SERVICE_DISCOVERY_MODE=docker_compose
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - ARCHON_AGENTS_PORT=${ARCHON_AGENTS_PORT:-8052}
      - ARCHON_SERVER_PORT=${ARCHON_SERVER_PORT:-8181}
    networks:
      - app-network
    healthcheck:
      test:
        [
          "CMD",
          "sh",
          "-c",
          'python -c "import urllib.request; urllib.request.urlopen(''http://localhost:${ARCHON_AGENTS_PORT:-8052}/health'')"',
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Agent Work Orders Service (Independent microservice for workflow execution)
  archon-agent-work-orders:
    profiles:
      - work-orders  # Only starts when explicitly using --profile work-orders
    build:
      context: ./python
      dockerfile: Dockerfile.agent-work-orders
      args:
        BUILDKIT_INLINE_CACHE: 1
        AGENT_WORK_ORDERS_PORT: ${AGENT_WORK_ORDERS_PORT:-8053}
    container_name: archon-agent-work-orders
    restart: unless-stopped
    depends_on:
      archon-server:
        condition: service_healthy
        restart: true
    ports:
      - "${AGENT_WORK_ORDERS_PORT:-8053}:${AGENT_WORK_ORDERS_PORT:-8053}"
    environment:
      - ENABLE_AGENT_WORK_ORDERS=true
      - SERVICE_DISCOVERY_MODE=docker_compose
      - STATE_STORAGE_TYPE=supabase
      - ARCHON_SERVER_URL=http://archon-server:${ARCHON_SERVER_PORT:-8181}
      - ARCHON_MCP_URL=http://archon-mcp:${ARCHON_MCP_PORT:-8051}
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_SERVICE_KEY=${SUPABASE_SERVICE_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - CLAUDE_CODE_OAUTH_TOKEN=${CLAUDE_CODE_OAUTH_TOKEN:-}
      - LOGFIRE_TOKEN=${LOGFIRE_TOKEN:-}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - AGENT_WORK_ORDERS_PORT=${AGENT_WORK_ORDERS_PORT:-8053}
      - CLAUDE_CLI_PATH=${CLAUDE_CLI_PATH:-claude}
      - GH_CLI_PATH=${GH_CLI_PATH:-gh}
      - GH_TOKEN=${GITHUB_PAT_TOKEN}
    networks:
      - app-network
    volumes:
      - ./python/src/agent_work_orders:/app/src/agent_work_orders # Hot reload for agent work orders
      - /tmp/agent-work-orders:/tmp/agent-work-orders # Temp files
    extra_hosts:
      - "host.docker.internal:host-gateway"
    healthcheck:
      test:
        [
          "CMD",
          "python",
          "-c",
          'import urllib.request; urllib.request.urlopen("http://localhost:${AGENT_WORK_ORDERS_PORT:-8053}/health")',
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Frontend
  archon-frontend:
    build: ./archon-ui-main
    container_name: archon-ui
    restart: unless-stopped
    ports:
      - "${ARCHON_UI_PORT:-3737}:3737"
    environment:
      # Don't set VITE_API_URL so frontend uses relative URLs through proxy
      # - VITE_API_URL=http://${HOST:-localhost}:${ARCHON_SERVER_PORT:-8181}
      - VITE_ARCHON_SERVER_PORT=${ARCHON_SERVER_PORT:-8181}
      - ARCHON_SERVER_PORT=${ARCHON_SERVER_PORT:-8181}
      - HOST=${HOST:-localhost}
      - PROD=${PROD:-false}
      - VITE_ALLOWED_HOSTS=${VITE_ALLOWED_HOSTS:-}
      - VITE_SHOW_DEVTOOLS=${VITE_SHOW_DEVTOOLS:-false}
      - DOCKER_ENV=true
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3737"]
      interval: 30s
      timeout: 10s
      retries: 3
    volumes:
      - ./archon-ui-main/src:/app/src
      - ./archon-ui-main/public:/app/public
    depends_on:
      archon-server:
        condition: service_healthy
        restart: true
      archon-mcp:
        condition: service_healthy
        restart: true

  # OCRmyPDF Service (Docker-based OCR)
  ocrmypdf-service:
    profiles:
      - ocr  # Only starts when explicitly using --profile ocr
    build:
      context: ./services/ocrmypdf
      dockerfile: Dockerfile
    container_name: ocrmypdf-service
    restart: unless-stopped
    ports:
      - "9002:9001"
    environment:
      - OCRMYPDF_IMAGE=${OCRMYPDF_IMAGE:-jbarlow83/ocrmypdf-alpine}
      - SERVICE_MODE=docker
      - PORT=9001
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    networks:
      - app-network
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock  # Docker socket for running OCRmyPDF containers
      - ocrmypdf-temp:/tmp  # Temp files for processing
    extra_hosts:
      - "host.docker.internal:host-gateway"
    healthcheck:
      test:
        [
          "CMD",
          "python",
          "-c",
          'import urllib.request; urllib.request.urlopen("http://localhost:9001/health")',
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Docling OCR Service (Archon-native with ARM64 support)
  docling-ocr:
    profiles:
      - ocr  # Only starts when explicitly using --profile ocr
    build:
      context: ./services/docling
      dockerfile: Dockerfile
    container_name: docling-ocr
    restart: unless-stopped
    ports:
      - "9000:9000"
    environment:
      - PYTHONUNBUFFERED=1
      - OMP_NUM_THREADS=4
      - HF_HOME=/models
      - TORCH_HOME=/models
      - DOCLING_ARTIFACTS_PATH=/models/docling
      - PORT=9000
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    networks:
      - app-network
    volumes:
      - docling-models:/models  # Model cache (persisted across restarts)
      - docling-temp:/tmp  # Temp files for processing
    extra_hosts:
      - "host.docker.internal:host-gateway"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Stirling PDF Service (Web-based batch OCR processing)
  stirling-pdf:
    profiles:
      - ocr  # Starts with all OCR services using --profile ocr
    image: stirlingtools/stirling-pdf:latest
    container_name: stirling-pdf
    restart: unless-stopped
    ports:
      - "${STIRLING_PDF_PORT:-9003}:8080"
    environment:
      - LANGS=en_GB,en_US
      - DOCKER_ENABLE_SECURITY=false  # Disable auth for local development
      - SYSTEM_DEFAULTLOCALE=en-GB
      - UI_APP_NAME=Archon PDF Tools
      - UI_HOME_DESCRIPTION=PDF processing and OCR powered by Archon
    networks:
      - app-network
    volumes:
      - stirling-pdf-training:/usr/share/tessdata  # Tesseract training data
      - stirling-pdf-configs:/configs  # Extra configurations
      - stirling-pdf-logs:/logs  # Log files
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/api/v1/info/status"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # LaTeX-OCR Service (Formula image to LaTeX conversion) - Native ARM64/AMD64
  latex-ocr:
    profiles:
      - ocr  # Starts with all OCR services using --profile ocr
    build:
      context: ./services/latex-ocr
      dockerfile: Dockerfile
    container_name: latex-ocr
    restart: unless-stopped
    ports:
      - "9001:9001"
    environment:
      - PYTHONUNBUFFERED=1
      - PORT=9001
    networks:
      - app-network
    volumes:
      - latex-ocr-models:/root/.cache/huggingface  # Model cache
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9001/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s  # Longer startup for model loading

  # Parser Service - Orchestrates Docling + LaTeX-OCR for complete PDF extraction
  parser-service:
    profiles:
      - ocr  # Starts with all OCR services using --profile ocr
    build:
      context: ./services/parser
      dockerfile: Dockerfile
    container_name: parser-service
    restart: unless-stopped
    ports:
      - "9004:9004"
    environment:
      - PYTHONUNBUFFERED=1
      - DOCLING_URL=http://docling-ocr:9000
      - LATEX_OCR_URL=http://latex-ocr:9001
      - PORT=9004
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    networks:
      - app-network
    depends_on:
      docling-ocr:
        condition: service_healthy
      latex-ocr:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import httpx; httpx.get('http://localhost:9004/health', timeout=5.0)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Marker - PDF to Markdown with Formulas & Tables (CPU-friendly)
  marker-pdf:
    profiles:
      - advanced-ocr
    build:
      context: ./services/marker
      dockerfile: Dockerfile
    container_name: marker-pdf
    restart: unless-stopped
    ports:
      - "${MARKER_PORT:-7100}:7000"
    environment:
      - PYTHONUNBUFFERED=1
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    networks:
      - app-network
    volumes:
      - marker-models:/root/.cache/huggingface  # Model cache
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 180s  # Longer startup for model loading

  # DeepSeek-OCR MLX Service (Mac M4 optimized - NATIVE SERVICE RECOMMENDED)
  # NOTE: This Docker service runs on CPU only. For Apple Metal GPU acceleration,
  # run the native Mac service instead: ~/Projects/archon/services/deepseek-ocr-mlx/start_service.sh
  # Configure via DEEPSEEK_OCR_MLX_URL=http://localhost:9005 in .env
  deepseek-ocr-mlx:
    profiles:
      - ocr  # Starts with all OCR services using --profile ocr
    image: python:3.12-slim
    container_name: deepseek-ocr-mlx
    restart: unless-stopped
    ports:
      - "9005:9005"
    environment:
      - PYTHONUNBUFFERED=1
      - PORT=9005
      - MODEL_NAME=mlx-community/DeepSeek-OCR-8bit
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    networks:
      - app-network
    volumes:
      - ./services/deepseek-ocr-mlx:/app
      - deepseek-mlx-models:/root/.cache/mlx  # Model cache
    working_dir: /app
    command: >
      bash -c "
      pip install -q mlx mlx-vlm fastapi uvicorn[standard] python-multipart Pillow pydantic &&
      uvicorn app:app --host 0.0.0.0 --port 9005
      "
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:9005/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 90s  # Longer for model download on first run
    extra_hosts:
      - "host.docker.internal:host-gateway"

  # NOTE: MinerU Docker service removed - now using native Mac service for Apple GPU acceleration
  # See python/start_mineru_service.sh and python/src/mineru_service/main.py
  # Configure via MINERU_SERVICE_URL=http://host.docker.internal:8055 in .env

networks:
  app-network:
    driver: bridge

volumes:
  ocrmypdf-temp:  # Temp files for OCRmyPDF processing
  docling-models:  # Docling model cache (HuggingFace models)
  docling-temp:  # Temp files for Docling processing
  stirling-pdf-training:  # Tesseract training data for Stirling PDF
  stirling-pdf-configs:  # Stirling PDF configurations
  stirling-pdf-logs:  # Stirling PDF logs
  marker-models:  # Marker model cache for formula and table extraction
  latex-ocr-models:  # LaTeX-OCR model cache (pix2tex models)
  deepseek-mlx-models:  # DeepSeek-OCR MLX model cache (mlx-community models)
  # NOTE: mineru-models volume removed - native service uses host filesystem
